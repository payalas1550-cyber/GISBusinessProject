{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22faf714-5165-4bc2-a4e1-276da40b2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd                # For working with data tables\n",
    "import geopandas as gpd            # For working with geographic data\n",
    "from shapely.geometry import Point # For creating point locations on the map\n",
    "import leafmap                     # For displaying interactive maps\n",
    "import os\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "import zipfile\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "# Start the timer for the entire operation\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a map centered on the United States, with a zoom level of 4\n",
    "m = leafmap.Map(center=[37.8, -96.9], zoom=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16511b06-52d8-49f9-87ba-034c35dcdb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for a shapefile of all US states\n",
    "url = \"https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_500k.zip\"\n",
    "\n",
    "# Parse the URL and get the path\n",
    "path = urlparse(url).path\n",
    "\n",
    "# Get the filename without extension\n",
    "filename = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "# Create the unzip directory if it doesn't exist\n",
    "unzip_dir = './extracted_files'\n",
    "os.makedirs(unzip_dir, exist_ok=True)\n",
    "\n",
    "# Path where you want to save the zip file\n",
    "zip_path = os.path.join(unzip_dir, f\"{filename}.zip\")\n",
    "\n",
    "# Download the shapefile zip\n",
    "urllib.request.urlretrieve(url, zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdc4e3-e1f2-49e2-abc9-521ff298af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the downloaded shapefile\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05318b8-ff8a-4fb5-91cd-493b198175d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the UniversityDirectory2023 CSV into a data frame\n",
    "csv_path_university = \"./UniversityData/UniversityDirectory2023.csv\"\n",
    "columns_to_use_university = [\"UNITID\", \"INSTNM\", \"ADDR\", \"CITY\", \"STABBR\", \"LONGITUD\", \"LATITUDE\"]\n",
    "df_university = pd.read_csv(csv_path_university, usecols=columns_to_use_university, encoding='ISO-8859-1')\n",
    "print(f\"There are {df_university.shape[0]} rows in this data frame!\")\n",
    "df_university.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b313ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the UniversityAwardedDegrees2023 CSV into a data frame\n",
    "csv_path_awarded_degrees = \"./UniversityData/UniversityAwardedDegrees2023.csv\"\n",
    "df_awarded_degrees = pd.read_csv(csv_path_awarded_degrees, usecols=[\"UNITID\", \"CTOTALT\"], encoding='ISO-8859-1')\n",
    "print(f\"There are {df_awarded_degrees.shape[0]} rows in this data frame!\")\n",
    "df_awarded_degrees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d40d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on UNITID\n",
    "df_merged = pd.merge(df_university, df_awarded_degrees, on=\"UNITID\", how=\"inner\")\n",
    "print(f\"There are {df_merged.shape[0]} rows in this data frame!\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadab71-dad7-4d55-87f1-b040ac2be0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.groupby(\"INSTNM\").agg({\n",
    "    'CTOTALT': 'sum',  # Sum of degrees awarded\n",
    "    'LATITUDE': 'first',  # You can also use 'mean' or 'median', if preferred\n",
    "    'LONGITUD': 'first'  # Similarly, 'mean' or 'median' can be used\n",
    "}).reset_index()\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert LATITUDE and LONGITUD to geometry points\n",
    "def make_point(row):\n",
    "    return Point(row['LONGITUD'], row['LATITUDE'])\n",
    "df_merged['geometry'] = df_merged.apply(make_point, axis=1)\n",
    "print(f\"There are {df_merged.shape[0]} rows in this data frame!\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the merged DataFrame into a GeoDataFrame\n",
    "gdf_university = gpd.GeoDataFrame(df_merged, geometry='geometry', crs=\"EPSG:4326\")\n",
    "gdf_university.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb2590-7f69-4575-9543-94f28b28ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING - THIS CAN TAKE A LONG TIME DEPENDING ON THE SPECS OF YOUR PC\n",
    "# Add the university point layer to the map\n",
    "#m.add_gdf(gdf_university, layer_name=\"All Universities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a10ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Shapefile for US States from the correct directory\n",
    "shapefile_path = \"./extracted_files/cb_2018_us_state_500k.shp\"\n",
    "gdf_states = gpd.read_file(shapefile_path)\n",
    "gdf_states.head()\n",
    "\n",
    "# Add the states with the degree totals to the map, symbolizing by the 'Total degrees awarded' column\n",
    "m.add_gdf(gdf_states, layer_name=\"States\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer for the spatial join\n",
    "spatial_join_start_time = time.time()\n",
    "\n",
    "# Perform a spatial join between the university data and the state shapefile\n",
    "gdf_joined = gpd.sjoin(gdf_university, gdf_states, how=\"inner\", op=\"within\")\n",
    "\n",
    "# Calculate and print the time taken for the spatial join\n",
    "spatial_join_end_time = time.time()\n",
    "spatial_join_duration = spatial_join_end_time - spatial_join_start_time\n",
    "print(f\"Time taken for spatial join: {spatial_join_duration:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf058ce-8175-4ffc-a1fc-84838f649b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the joined data by state and sum the degrees awarded\n",
    "gdf_state_degrees = gdf_joined.groupby(\"STUSPS\")[\"CTOTALT\"].sum().reset_index()\n",
    "\n",
    "# Merge the aggregated data back into the state boundaries GeoDataFrame\n",
    "gdf_states = gdf_states.merge(gdf_state_degrees, left_on=\"STUSPS\", right_on=\"STUSPS\", how=\"left\")\n",
    "print(gdf_states.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc3c37-bb47-405e-9cca-b54cef61cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 'Name' from the shapefile for the full state names and clean up the DataFrame\n",
    "gdf_states[\"State Name\"] = gdf_states[\"NAME\"]\n",
    "gdf_states[\"State Abbreviation\"] = gdf_states[\"STUSPS\"]\n",
    "gdf_states[\"Total degrees awarded\"] = gdf_states[\"CTOTALT\"]\n",
    "\n",
    "# Drop unnecessary columns and keep the relevant ones\n",
    "gdf_states = gdf_states[[\"State Name\", \"State Abbreviation\", \"Total degrees awarded\", \"geometry\"]]\n",
    "\n",
    "# Add the states with the degree totals to the map, symbolizing by the 'Total degrees awarded' column\n",
    "m.add_gdf(gdf_states, \n",
    "          layer_name=\"States with Degrees\",\n",
    "          color_by=\"Total degrees awarded\",\n",
    "          color_scale=\"YlOrRd\",\n",
    "         )\n",
    "\n",
    "# Drop unnecessary columns and keep the relevant ones\n",
    "#gdf_states = gdf_states[[\"State Name\", \"State Abbreviation\", \"Total degrees awarded\"]]\n",
    "\n",
    "m.add_labels(\n",
    "    gdf_states,\n",
    "    column=\"Total degrees awarded\",\n",
    "    label_font_size=12,\n",
    "    label_color=\"black\",\n",
    "    label_offset=[0, 0],\n",
    "    layer_name=\"Degree Labels\"\n",
    ")\n",
    "\n",
    "# Show the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114229d-e15e-4422-b36e-2eae77c1c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some interesting facts\n",
    "num_rows, num_columns = df_merged.shape\n",
    "num_cells = num_rows * num_columns\n",
    "\n",
    "print(f\"Total number of rows: {num_rows:,}\")\n",
    "print(f\"Total number of columns: {num_columns:,}\")\n",
    "print(f\"Total number of cells: {num_cells:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f908187-831b-4bef-93eb-2a8f8e8dc457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of all degrees awarded across all universities\n",
    "total_degrees_awarded = gdf_states[\"Total degrees awarded\"].sum()\n",
    "\n",
    "# Print the result with commas for readability\n",
    "print(f\"Total degrees awarded across all states: {total_degrees_awarded:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c82fb-6745-4d54-abfe-c61af4739ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the full operation\n",
    "end_time = time.time()\n",
    "total_duration = end_time - start_time\n",
    "\n",
    "# Print the total operation time and format with commas\n",
    "print(f\"Total operation time: {total_duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc209ee7-d563-45c8-86dd-f7370ff620bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject the GeoDataFrame to EPSG:4326\n",
    "gdf_states = gdf_states.to_crs(epsg=4326)\n",
    "\n",
    "# Export the GeoDataFrame to GeoJSON without the CRS field\n",
    "gdf_states.to_file(\"states_degrees_awarded.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed8a98-5037-48d9-b409-c8ac3591e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually upload your GeoJSON to ArcGIS Online: https://www.arcgis.com/home/content.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e2cd2-21d6-4409-bf09-c4bf3a776631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import that layer into a Map: https://www.arcgis.com/apps/mapviewer/index.html\n",
    "# Make sure to SAVE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35ae7d-8415-4850-bf2d-369bf9927afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you repeat thsi exercise using US counties?!\n",
    "# https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_500k.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
